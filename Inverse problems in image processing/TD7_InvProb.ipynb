{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial \\#7 (23 Feb. 2024)\n",
    "\n",
    "Faisal Jayousi \n",
    "\n",
    "jayousi@unice.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is DeepInverse all about?\n",
    "DeepInverse is a Pytorch based Python module for solving imaging inverse problems with Deep Learning. If provides a range of linear and non-linear forward operators, such as blurring, denoising and downsampling.\n",
    "\n",
    "## Importing DeepInverse\n",
    "* You need to install the DeepInverse module for this tutorial: ```pip install deepinv```\n",
    "* To import it: use ```import deepinv```\n",
    "* Documentation: https://deepinv.github.io/deepinv/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Raffaele\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Raffaele\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import deepinv as dinv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import deepinv as dinv\n",
    "from torch.utils.data import DataLoader\n",
    "from deepinv.optim.data_fidelity import L1\n",
    "from deepinv.optim.prior import PnP\n",
    "from deepinv.unfolded import unfolded_builder\n",
    "from deepinv.training_utils import train, test\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISTA\n",
    "\n",
    "The subject of this tutorial is LISTA (Learned Iterative Soft-Thresholding Algorithm). The main difference with the classical ISTA algorithm is that the thresholding parameters of the proximal operator are learned. For a use-case in compressed sensing, see https://deepinv.github.io/deepinv/auto_examples/unfolded/demo_LISTA.html.\n",
    "\n",
    "**NB**: Using a GPU for this tutorial is recommended. However, the parameters have been modestly adjusted to ensure efficient execution on a CPU in minimal time.\n",
    "\n",
    "The steps are as follows:\n",
    "1. Data generation: as a first approach, we will use the well-known MNIST dataset. It can be downloaded using ```datasets.MNIST()```. See the documentation for more details on the arguments.\n",
    "2. Generate blurred images: you can use ```dinv.datasets.generate_dataset()```. An appropriate blurring model needs to be defined first. For simplicity, choose a gaussian kernel with $\\sigma=3$.\n",
    "3. Load the data using PyTorch's dataloaders. Don't forget to shuffle the training data. You may use DeepInverse's ```datasets.HDF5Dataset()```.\n",
    "4. Train using the training data. See DeepInverse's ```training_utils```.\n",
    "5. Test your model on the test dataset. Plot the learned stepsize and regularisastion parameter.\n",
    "6. Test your model on a generated SMLM image. How well does it work?\n",
    "7. Redo everything but with generated SMLM images (use ~250 images for training).\n",
    "\n",
    "\n",
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate an SMLM image\n",
    "def generate_ground_truth(n: int, n_mol: int, margin: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    n: shape of output\n",
    "    n_mol: number of molecules\n",
    "    margin: to avoid placing molecules near the edges\n",
    "    \"\"\"\n",
    "    gt = np.zeros((n, n), dtype=np.double)\n",
    "    for _ in np.arange(n_mol):\n",
    "        i = random.randint(margin, n-margin)\n",
    "        j = random.randint(margin, n-margin)\n",
    "        gt[i, j] = 255.\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(234)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\".\")\n",
    "ORIGINAL_DATA_DIR = BASE_DIR\n",
    "DATA_DIR = BASE_DIR\n",
    "RESULTS_DIR = BASE_DIR\n",
    "CKPT_DIR = BASE_DIR\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_operator(x):\n",
    "    s = 3\n",
    "    t = np.concatenate((np.arange(0, x.shape[0]/2+1), np.arange(-x.shape[0]/2,-1)))\n",
    "    Y, X = np.meshgrid(t,t)\n",
    "    h = h=np.exp(-(X**2+Y**2)/(2.0*float(s)**2))\n",
    "    h = h/np.sum(h)  #Is the operator, instead of A, consider h\n",
    "    return np.real(np.fft.ifft2(np.fft.fft2(h) * np.fft.fft2(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:03<00:00, 2855722.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\train-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2360215.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\train-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:02<00:00, 653627.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to .\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2278498.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to .\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_size = 28\n",
    "n_channels = 1\n",
    "operation = \"compressed-sensing\"\n",
    "train_dataset_name = \"MNIST_train\"\n",
    "\n",
    "# Generate training and evaluation datasets in HDF5 folders and load them.\n",
    "train_test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_base_dataset = datasets.MNIST(\n",
    "    root=ORIGINAL_DATA_DIR, train=True, transform=train_test_transform, download=True\n",
    ")\n",
    "test_base_dataset = datasets.MNIST(\n",
    "    root=ORIGINAL_DATA_DIR, train=False, transform=train_test_transform, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing train measurement vectors from base dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing test measurement vectors from base dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 100.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been saved in MNIST_train\\compressed-sensing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous\n",
    "# data loading.\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "\n",
    "\n",
    "physics = dinv.physics.Blur(dinv.physics.blur.gaussian_blur(sigma=(1, 1), angle=0), padding='circular', device='cpu')\n",
    "my_dataset_name = \"demo_LISTA\"\n",
    "n_images_max = (\n",
    "    1000 if torch.cuda.is_available() else 200\n",
    ")  # maximal number of images used for training\n",
    "measurement_dir = DATA_DIR / train_dataset_name / operation\n",
    "generated_datasets_path = dinv.datasets.generate_dataset(\n",
    "    train_dataset=train_base_dataset,\n",
    "    test_dataset=test_base_dataset,\n",
    "    physics=physics,\n",
    "    device=device,\n",
    "    save_dir=measurement_dir,\n",
    "    train_datapoints=n_images_max,\n",
    "    test_datapoints=8,\n",
    "    num_workers=num_workers,\n",
    "    dataset_filename=str(my_dataset_name),\n",
    ")\n",
    "\n",
    "train_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=True)\n",
    "test_dataset = dinv.datasets.HDF5Dataset(path=generated_datasets_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raffaele\\anaconda3\\Lib\\site-packages\\deepinv\\unfolded\\unfolded.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [nn.Parameter(torch.tensor(el).to(device)) for el in param_value]\n"
     ]
    }
   ],
   "source": [
    "# Select the data fidelity term\n",
    "data_fidelity = L1()\n",
    "\n",
    "# Set up the trainable denoising prior; here, the soft-threshold in a wavelet basis.\n",
    "# If the prior is initialized with a list of length max_iter,\n",
    "# then a distinct weight is trained for each PGD iteration.\n",
    "# For fixed trained model prior across iterations, initialize with a single model.\n",
    "max_iter = 10 if torch.cuda.is_available() else 10  # Number of unrolled iterations\n",
    "level = 2\n",
    "prior = [\n",
    "    PnP(denoiser=dinv.models.WaveletPrior(wv=\"db8\", level=level, device=device))\n",
    "    for i in range(max_iter)\n",
    "]\n",
    "\n",
    "# Unrolled optimization algorithm parameters\n",
    "\n",
    "lamb = [1.0] * max_iter  # initialization of the regularization parameter.\n",
    "# A distinct lamb is trained for each iteration.\n",
    "\n",
    "stepsize = [1.0] * max_iter  # initialization of the stepsizes.\n",
    "# A distinct stepsize is trained for each iteration.\n",
    "\n",
    "sigma_denoiser_init = 0.05\n",
    "sigma_denoiser = [sigma_denoiser_init * torch.ones(level, 3)] * max_iter\n",
    "# A distinct sigma_denoiser is trained for each iteration.\n",
    "\n",
    "params_algo = {  # wrap all the restoration parameters in a 'params_algo' dictionary\n",
    "    \"stepsize\": stepsize,\n",
    "    \"g_param\": sigma_denoiser,\n",
    "    \"lambda\": lamb,\n",
    "}\n",
    "\n",
    "trainable_params = [\n",
    "    \"g_param\",\n",
    "    \"stepsize\",\n",
    "    \"lambda\",\n",
    "]  # define which parameters from 'params_algo' are trainable\n",
    "\n",
    "# Define the unfolded trainable model.\n",
    "model = unfolded_builder(\n",
    "    iteration=\"PGD\",\n",
    "    params_algo=params_algo.copy(),\n",
    "    trainable_params=trainable_params,\n",
    "    data_fidelity=data_fidelity,\n",
    "    max_iter=max_iter,\n",
    "    prior=prior,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as in the previous tutorials, we will solve the following problem $$\\min_x \\frac{1}{2}\\|Ax-y\\|_2^2 + \\lambda\\|x\\|_1$$\n",
    "\n",
    "In this tutorial, we will focus exclusively on $\\ell^1$ regularisation. However, the module provides a wide range of intriguing priors, both classical and learnable. For further details, refer to https://deepinv.github.io/deepinv/deepinv.models.html. Additionally, we will optimise the selection of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 4\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "# Choose optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Choose supervised training loss\n",
    "losses = [dinv.loss.SupLoss(metric=dinv.metric.mse())]\n",
    "\n",
    "# Logging parameters\n",
    "verbose = True\n",
    "wandb_vis = False  # plot curves and images in Weight&Bias\n",
    "\n",
    "# Batch sizes and data loaders\n",
    "train_batch_size = 1\n",
    "test_batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, num_workers=num_workers, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 80 trainable parameters\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: './24-02-23-11:58:18'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      3\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[0;32m      4\u001b[0m     eval_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[0;32m      5\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m      6\u001b[0m     losses\u001b[38;5;241m=\u001b[39mlosses,\n\u001b[0;32m      7\u001b[0m     physics\u001b[38;5;241m=\u001b[39mphysics,\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m      9\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     10\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deepinv\\training_utils.py:335\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, epochs, losses, eval_dataloader, physics, optimizer, grad_clip, scheduler, device, ckp_interval, eval_interval, save_path, verbose, unsupervised, plot_images, plot_metrics, wandb_vis, wandb_setup, online_measurements, plot_measurements, check_grad, ckpt_pretrained, fact_losses, freq_plot)\u001b[0m\n\u001b[0;32m    332\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;66;03m# Saving the model\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m     save_model(\n\u001b[0;32m    336\u001b[0m         epoch,\n\u001b[0;32m    337\u001b[0m         model,\n\u001b[0;32m    338\u001b[0m         optimizer,\n\u001b[0;32m    339\u001b[0m         ckp_interval,\n\u001b[0;32m    340\u001b[0m         epochs,\n\u001b[0;32m    341\u001b[0m         loss_history,\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28mstr\u001b[39m(save_path),\n\u001b[0;32m    343\u001b[0m         eval_psnr\u001b[38;5;241m=\u001b[39meval_psnr \u001b[38;5;28;01mif\u001b[39;00m perform_eval \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    344\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb_vis:\n\u001b[0;32m    347\u001b[0m     wandb\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deepinv\\utils\\nn.py:185\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(epoch, model, optimizer, ckp_interval, epochs, loss, save_path, eval_psnr)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model\u001b[39m(\n\u001b[0;32m    182\u001b[0m     epoch, model, optimizer, ckp_interval, epochs, loss, save_path, eval_psnr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    183\u001b[0m ):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m ckp_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m epochs:\n\u001b[1;32m--> 185\u001b[0m         os\u001b[38;5;241m.\u001b[39mmakedirs(save_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    187\u001b[0m         state \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: epoch,\n\u001b[0;32m    189\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m    190\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss,\n\u001b[0;32m    191\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m    192\u001b[0m         }\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m eval_psnr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: './24-02-23-11:58:18'"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    epochs=epochs,\n",
    "    losses=losses,\n",
    "    physics=physics,\n",
    "    optimizer=optimizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on SMLM image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = generate_ground_truth(28, 4, 4)\n",
    "gt = torch.from_numpy(gt).to(torch.float)\n",
    "\n",
    "\n",
    "blurred_image = ...\n",
    "out = ...\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(gt, cmap='gray')\n",
    "plt.subplot(132)\n",
    "plt.imshow(blurred_image[0, 0], cmap=\"gray\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(out.detach().numpy()[0, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining on SMLM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
