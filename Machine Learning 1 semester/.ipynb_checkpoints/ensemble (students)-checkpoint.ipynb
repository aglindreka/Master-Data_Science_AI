{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL01rcyShBlp"
   },
   "source": [
    "Import the libraries needed and the datasets to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4GENppIutd4",
    "outputId": "f23f5637-6348-4ec3-abfd-9da93782f544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (0.20.1)\n"
     ]
    }
   ],
   "source": [
    "# To install the Python graphviz package, you may use \"pip\" as follows\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from mlxtend) (1.21.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from mlxtend) (61.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\raffaele\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# To install the Python mlxtend package, you may use \"pip\" as follows\n",
    "!pip install mlxtend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "H4_scPqcQkqb"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.base import clone\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "# install the package python-graphviz\n",
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qGwu_8tSR8xn"
   },
   "outputs": [],
   "source": [
    "# load the Iris and MNIST datasets\n",
    "iris_data = load_iris()\n",
    "mnist_data = load_digits()\n",
    "\n",
    "X = iris_data.data\n",
    "y = iris_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5HRzgZqhNs9"
   },
   "source": [
    "## Train a simple tree model using the Iris data set and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLbOX6VKhNWV",
    "outputId": "ebc808d3-bb46-4d6e-834d-c5eab05123db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMFbhAoCvoT1"
   },
   "source": [
    "Export the tree into a pdf file and view the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to view the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES5Azey3wkza"
   },
   "source": [
    "## Draw the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdJOewGlwleh"
   },
   "source": [
    "The splitting is based on the Gini index as explained in the lecture. At each node, we wee :\n",
    "\n",
    "- the attribute that is used for the splitting\n",
    "\n",
    "- the value of the Gini index\n",
    "\n",
    "- the number of processed samples\n",
    "\n",
    "- the proportions of the classes\n",
    "\n",
    "- the class that is decided at this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFAHGIgdwxUp"
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=iris_data.feature_names,  \n",
    "                         class_names=iris_data.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0N-hzAS0au_"
   },
   "source": [
    "## Simulate a randomforest ensemble model using multiple decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ny4ZITPzSEWD"
   },
   "source": [
    "Create a list of 5 decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bSB24EFvR_No"
   },
   "outputs": [],
   "source": [
    "# create a list of nb decision trees\n",
    "nb = 50\n",
    "decision_trees = [DecisionTreeClassifier() for i in range(nb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7-shv0iSv-W"
   },
   "source": [
    "Train the decision trees on different subsets of the Iris data\n",
    "\n",
    "Have a look to the [sklearn.model_selection.KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ueLXFtuHTsjD"
   },
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "\n",
    "# use Kfold to split the training set into nb random subsets\n",
    "kf = KFold(n_splits=nb)\n",
    "subsets = []\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_subset = X_train[test_index]\n",
    "    y_subset = y_train[test_index]\n",
    "    subsets.append((X_subset, y_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the length of each element of the subset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dptD9tgvkj79"
   },
   "outputs": [],
   "source": [
    "Train each decision trees on different subsets of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(decision_trees)):\n",
    "    decision_trees[i].fit(subsets[i][0], subsets[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATKrDdJs3Wuu"
   },
   "source": [
    "Draw one of the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8NZogpxi3Z2z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.75, 'X[2] <= 3.2\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(0.25, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.75, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using what you learned in the first section about graphviz draw one of the trees\n",
    "tree.plot_tree(decision_trees[0]) #to get the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJcZIIYSUxmz"
   },
   "source": [
    "Predict using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nO1qYOvtbp4O",
    "outputId": "aa76224e-1353-47f7-f108-e66fa9bf6318"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2,\n",
       "        0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "        1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2,\n",
       "        0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "        1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1]),\n",
       " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
       "        1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1]),\n",
       " array([2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "        1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2,\n",
       "        0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2,\n",
       "        0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2]),\n",
       " array([2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,\n",
       "        2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2]),\n",
       " array([2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2,\n",
       "        1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1]),\n",
       " array([2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2,\n",
       "        0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2,\n",
       "        0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0,\n",
       "        0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0]),\n",
       " array([2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
       "        1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1]),\n",
       " array([2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2,\n",
       "        0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2]),\n",
       " array([2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2,\n",
       "        0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1]),\n",
       " array([2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "        1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1]),\n",
       " array([2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2,\n",
       "        0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2]),\n",
       " array([2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on the test set using the diff√©rent decision trees\n",
    "predictions = []\n",
    "for tree in decision_trees:\n",
    "    pred = tree.predict(X_test)\n",
    "    predictions.append(pred)\n",
    "\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9943333333333333\n",
      "0.760899394722383\n"
     ]
    }
   ],
   "source": [
    "#What is the mean and standard deviation of the predictions?\n",
    "print(np.mean(predictions))\n",
    "print(np.std(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNE-A6ucU1b0",
    "outputId": "5226b85b-46d6-49e4-94d7-4799563dd1b3"
   },
   "outputs": [],
   "source": [
    "#edit your array so that the predictions for each sample in one list (one row should represent the\n",
    "#predictions of one sample by all nb trees) you can use numpy and the transpose function\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WCc4MM4VHyV"
   },
   "source": [
    "Combine the predictions using majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpM7chlpU2su"
   },
   "outputs": [],
   "source": [
    "# define a function to combine predictions using majority voting\n",
    "def majority_vote(predictions):\n",
    "    # count the number of occurrences of each prediction\n",
    "    count = Counter(predictions)\n",
    "    # return the prediction with the most occurrences\n",
    "    return max(count, key=count.get)\n",
    "print(majority_vote(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3nIJYQFwc9QH",
    "outputId": "802a38c7-0c81-444c-a664-e7001226f5ac"
   },
   "outputs": [],
   "source": [
    "# combine the predictions using majority voting\n",
    "final_predictions = []\n",
    "for prediction in predictions:\n",
    "    final_predictions.append(majority_vote(prediction))\n",
    "\n",
    "# print the final predictions\n",
    "print('Final predictions:', final_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFi1itcZVQyP"
   },
   "source": [
    "Evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lObPvxrVNU8",
    "outputId": "0530758b-352a-484a-801c-6708a34d4227"
   },
   "outputs": [],
   "source": [
    "# evaluate the performance of the random forests model\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print('Random forests model performance:')\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J_cpp590qXD"
   },
   "source": [
    "Repeat the simulation but using teh random-forest classifier model instead of multiple decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoCNCXpf02Yq",
    "outputId": "f1a1769e-a23d-4a5a-fbcb-aa88d2e19600"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "\n",
    "# Create a random forest classifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the classifier on the training data\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "\n",
    "\n",
    "# Evaluate the performance of the boosted classifier\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaF4XE8U5Ggi"
   },
   "source": [
    "Perform boosting of a simple tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "3POXZvdj5G6l",
    "outputId": "4df029a5-5ba9-4692-dc90-e68e10762901"
   },
   "outputs": [],
   "source": [
    "# Create a base DecisionTreeClassifierclassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a weighting function\n",
    "def weight(y, y_pred):\n",
    "  # Calculate the error rate\n",
    "  error = 1.0 - accuracy_score(y, y_pred)\n",
    "  # Set the weight to be inversely proportional to the error rate\n",
    "  w = (1.0 - error) / 1.0\n",
    "  return w\n",
    "\n",
    "\n",
    "# Create a list to store the boosted classifiers\n",
    "boosted_classifiers = []\n",
    "\n",
    "# Create a list to store the weights of the boosted classifiers\n",
    "weights = []\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "\n",
    "#clf = DecisionTreeClassifier()\n",
    "#clf = clf.fit(X_train,y_train)\n",
    "#y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Boost the classifier n times\n",
    "n = 5\n",
    "# use Kfold to split the training set into 5 random subsets\n",
    "kf = KFold(n_splits=n)\n",
    "subsets = []\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_subset = X_train[test_index]\n",
    "    y_subset = y_train[test_index]\n",
    "    subsets.append((X_subset, y_subset))\n",
    "\n",
    "for i in range(n):\n",
    "  # Clone the base classifier\n",
    "  clf_i = clone(clf)\n",
    "\n",
    "  # Train the cloned classifier on the training data\n",
    "  clf_i.fit(subsets[i][0], subsets[i][1])\n",
    "\n",
    "  # Make predictions on the training data\n",
    "  y_pred = clf_i.predict(X_train)\n",
    "\n",
    "  # Calculate the weight of the classifier\n",
    "  w = weight(y_train, y_pred)\n",
    "\n",
    "  # Add the classifier and its weight to the lists\n",
    "  boosted_classifiers.append(clf_i)\n",
    "  weights.append(w)\n",
    "\n",
    "\n",
    "print(weights)\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = np.zeros(len(X_test))\n",
    "\n",
    "# Loop through the boosted classifiers and make predictions\n",
    "for i in range(n):\n",
    "  y_pred += weights[i] * boosted_classifiers[i].predict(X_test)\n",
    "y_pred = y_pred/5\n",
    "\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "\n",
    "# Evaluate the performance of the boosted classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-o8lx_v08kC"
   },
   "source": [
    "Apply Adaboosting to boost the performance of your random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-Za0PJ_1C0Q",
    "outputId": "5fd129d1-b480-4dda-fe27-981690ce52df"
   },
   "outputs": [],
   "source": [
    "# Boost the random forest model using AdaBoost\n",
    "\n",
    "\n",
    "# Train the boosted classifier on the training data\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "\n",
    "\n",
    "# Evaluate the performance of the boosted classifier\n",
    "accuracy = boosted_clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGlytoA9nBkY"
   },
   "source": [
    "Use mlxtend to plot the separation of the as in the example available [here](http://rasbt.github.io/mlxtend/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
